[![View article](https://img.shields.io/badge/Data_Science_Simplified-View_article-blue)](https://mathdatasimplified.com/2023/06/17/how-to-structure-a-data-science-project-for-readability-and-transparency-2/) [![View on YouTube](https://img.shields.io/badge/YouTube-Watch%20on%20Youtube-red?logo=youtube)](https://youtu.be/TzvcPi3nsdw) 

# Directory templates for Data Science projects

## Why?
It is important to structure your data science project based on a certain standard so that your teammates can easily maintain and modify your project.

This repository provides a template that incorporates best practices to create a maintainable and reproducible data science project.

## How are the templates organized?

The templates are organized in different branches, where each template is expected to be used along with a pre-determined set of tools. Depending on your approach (e.g., whether you want to use a cloud-based or on-premise ML project), you might want to use one template over others. In any case, the directory structure should not vary drastically.

## About this approach

The `aws-sagemaker` branch provides to you a directory structure to work with the Amazon SageMaker, an end-to-end cloud-based ML framework offered by Amazon Web Services (AWS). The following tools are expected to be used:

| Functionality  | Tool | Comments | Links |
|   ---               |        ---   |     ---   | --- |
| Package management |   Poetry | | [ðŸ”—](https://mathdatasimplified.com/poetry-a-better-way-to-manage-python-dependencies) [ðŸ”—](https://towardsdatascience.com/how-to-effortlessly-publish-your-python-package-to-pypi-using-poetry-44b305362f9f) |
| Config file manager | Hydra | Stop Hard Coding in a Data Science Project â€“ Use Config Files Instead | [ðŸ”—](https://mathdatasimplified.com/stop-hard-coding-in-a-data-science-project-use-configuration-files-instead) [ðŸ”—](https://hydra.cc/) |
| Data version control | Amazon S3 | Manage configuration files | [ðŸ”—](https://aws.amazon.com/s3) |

* [pre-commit plugins](https://pre-commit.com/): Automate code reviewing formatting
* [pdoc](https://github.com/pdoc3/pdoc): Automatically create an API documentation for your project

## Project Structure
```bash
.
â”œâ”€â”€ config                      
â”‚   â”œâ”€â”€ main.yaml                   # Main configuration file
â”‚   â”œâ”€â”€ model                       # Configurations for training model
â”‚   â”‚   â”œâ”€â”€ model1.yaml             # First variation of parameters to train model
â”‚   â”‚   â””â”€â”€ model2.yaml             # Second variation of parameters to train model
â”‚   â””â”€â”€ process                     # Configurations for processing data
â”‚       â”œâ”€â”€ process1.yaml           # First variation of parameters to process data
â”‚       â””â”€â”€ process2.yaml           # Second variation of parameters to process data
â”œâ”€â”€ data            
â”‚   â”œâ”€â”€ final                       # data after training the model
â”‚   â”œâ”€â”€ processed                   # data after processing
â”‚   â”œâ”€â”€ raw                         # raw data
â”‚   â””â”€â”€ raw.dvc                     # DVC file of data/raw
â”œâ”€â”€ docs                            # documentation for your project
â”œâ”€â”€ .gitignore                      # ignore files that cannot commit to Git
â”œâ”€â”€ Makefile                        # store useful commands to set up the environment
â”œâ”€â”€ models                          # store models
â”œâ”€â”€ notebooks                       # store notebooks
â”œâ”€â”€ .pre-commit-config.yaml         # configurations for pre-commit
â”œâ”€â”€ pyproject.toml                  # dependencies for poetry
â”œâ”€â”€ README.md                       # describe your project
â”œâ”€â”€ src                             # store source code
â”‚   â”œâ”€â”€ __init__.py                 # make src a Python module 
â”‚   â”œâ”€â”€ process.py                  # process data before training model
â”‚   â””â”€â”€ train_model.py              # train model
â””â”€â”€ tests                           # store tests
    â”œâ”€â”€ __init__.py                 # make tests a Python module 
    â”œâ”€â”€ test_process.py             # test functions for process.py
    â””â”€â”€ test_train_model.py         # test functions for train_model.py
```

## How to use this project

1. Install Cookiecutter:
    ```bash
    pip install cookiecutter
    ```
1. Create a project based on the template:
    ```bash
    cookiecutter https://github.com/khuyentran1401/data-science-template --checkout aws-sagemaker
    ```

